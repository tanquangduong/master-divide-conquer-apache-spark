# master-divide-conquer-apache-spark
Master Divide and Conquer algorithms with Apache Spark and Python



## ✅ Setup Env
- Create Python environment\
`conda create -n env_name python=3.10`\
`conda activate env_name`
- Create Python environment\
`pip install -r .\path_to_requirements\requirements.txt`

## ✅ Install and Setup Java, Apache Spark, Hadoop, Pyspark
- [Installation  guide](https://www.datacamp.com/tutorial/installation-of-pyspark#windows-installation)
- In the 'Variable Environment', we should have:
  - 'User variables':
    - Spark_home: C:\spark\spark-3.4.0-bin-hadoop3
    - hadoop_home: C:\winutils\hadoop-3.0.0
    - JAVA_HOME: C:\Program Files\Java\jdk-20
  - 'System variable': In the 'path' variable, add:
    - C:\spark\spark-3.4.0-bin-hadoop3\bin
    - C:\Program Files\Java\jdk-20\bin
    - C:\winutils\hadoop-3.0.0\bin